#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†å·¥å…·æ¨¡å—
è´Ÿè´£æœ¬åœ°æ•°æ®çš„åŠ è½½ã€ç®¡ç†å’Œäº¤äº’å¼é€‰æ‹©
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from utils import safe_list_input, safe_text_input

def get_local_data_summary() -> Dict[str, List[str]]:
    """è·å–æœ¬åœ°å·²ä¸‹è½½æ•°æ®æ‘˜è¦"""
    data_dir = "data"
    local_data = {}
    
    if not os.path.exists(data_dir):
        print(f"ğŸ“ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return local_data
    
    try:
        for symbol_dir in os.listdir(data_dir):
            symbol_path = os.path.join(data_dir, symbol_dir)
            
            # è·³è¿‡éç›®å½•æ–‡ä»¶å’Œç¼“å­˜ç›®å½•
            if not os.path.isdir(symbol_path) or symbol_dir == 'cache':
                continue
            
            intervals = []
            try:
                for file in os.listdir(symbol_path):
                    if file.endswith('.csv') or file.endswith('.pkl'):
                        # æå–æ—¶é—´å‘¨æœŸä¿¡æ¯
                        # æ–‡ä»¶åæ ¼å¼: SYMBOL_INTERVAL.csv æˆ– SYMBOL_INTERVAL.pkl
                        interval = file.replace(f"{symbol_dir}_", "").replace(".csv", "").replace(".pkl", "")
                        if interval and interval not in intervals:
                            intervals.append(interval)
                
                if intervals:
                    local_data[symbol_dir] = sorted(intervals, key=lambda x: _sort_interval_key(x))
                    
            except Exception as e:
                print(f"âš ï¸ è¯»å– {symbol_dir} ç›®å½•å¤±è´¥: {e}")
                continue
    
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®ç›®å½•å¤±è´¥: {e}")
        return {}
    
    return local_data

def _sort_interval_key(interval: str) -> int:
    """é—´éš”æ’åºé”®å‡½æ•°"""
    # å°†æ—¶é—´é—´éš”è½¬æ¢ä¸ºåˆ†é’Ÿæ•°ç”¨äºæ’åº
    interval_minutes = {
        '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
        '1h': 60, '2h': 120, '4h': 240, '6h': 360, '8h': 480, '12h': 720,
        '1d': 1440, '3d': 4320, '1w': 10080, '1M': 43200
    }
    return interval_minutes.get(interval, 99999)

def load_local_data(symbol: str, interval: str) -> Optional[pd.DataFrame]:
    """åŠ è½½æœ¬åœ°æ•°æ®"""
    data_dir = "data"
    symbol_path = os.path.join(data_dir, symbol)
    
    if not os.path.exists(symbol_path):
        print(f"âŒ å¸ç§ç›®å½•ä¸å­˜åœ¨: {symbol_path}")
        return None
    
    # å°è¯•åŠ è½½PKLæ–‡ä»¶ï¼ˆä¼˜å…ˆï¼‰å’ŒCSVæ–‡ä»¶
    pkl_file = os.path.join(symbol_path, f"{symbol}_{interval}.pkl")
    csv_file = os.path.join(symbol_path, f"{symbol}_{interval}.csv")
    
    try:
        df = None
        
        # ä¼˜å…ˆåŠ è½½PKLæ–‡ä»¶ï¼ˆæ›´å¿«ï¼‰
        if os.path.exists(pkl_file):
            print(f"ğŸ“ åŠ è½½æœ¬åœ°æ•°æ®: {symbol} {interval} (pickleæ ¼å¼)")
            df = pd.read_pickle(pkl_file)
            
        elif os.path.exists(csv_file):
            print(f"ğŸ“ åŠ è½½æœ¬åœ°æ•°æ®: {symbol} {interval} (csvæ ¼å¼)")
            df = pd.read_csv(csv_file)
            
            # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨å¹¶æ­£ç¡®æ ¼å¼åŒ–
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
            elif 'datetime' in df.columns:
                df['timestamp'] = pd.to_datetime(df['datetime'])
                df.drop('datetime', axis=1, inplace=True)
            else:
                print("âš ï¸ æœªæ‰¾åˆ°æ—¶é—´æˆ³åˆ—ï¼Œå°è¯•ä»ç´¢å¼•åˆ›å»º")
                if df.index.name == 'datetime' or isinstance(df.index, pd.DatetimeIndex):
                    df.reset_index(inplace=True)
                    df.rename(columns={'index': 'timestamp'}, inplace=True)
                    
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {symbol} {interval}")
            print(f"   æŸ¥æ‰¾è·¯å¾„: {pkl_file} æˆ– {csv_file}")
            return None
        
        if df is None:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {symbol} {interval}")
            return None
        
        # æ•°æ®éªŒè¯å’Œæ¸…ç†
        original_len = len(df)
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"âŒ æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            return None
        
        # æ•°æ®æ¸…ç†
        # 1. åˆ é™¤åŒ…å«NaNçš„è¡Œ
        df = df.dropna(subset=required_columns)
        
        # 2. åˆ é™¤å¼‚å¸¸æ•°æ®ï¼ˆä»·æ ¼ä¸º0æˆ–è´Ÿæ•°ï¼‰
        price_columns = ['open', 'high', 'low', 'close']
        for col in price_columns:
            df = df[df[col] > 0]
        
        # 3. æ£€æŸ¥OHLCé€»è¾‘
        df = df[(df['high'] >= df['low']) & 
                (df['high'] >= df['open']) & 
                (df['high'] >= df['close']) & 
                (df['low'] <= df['open']) & 
                (df['low'] <= df['close'])]
        
        # 4. åˆ é™¤é‡å¤æ—¶é—´æˆ³
        if 'timestamp' in df.columns:
            df = df.drop_duplicates(subset=['timestamp'], keep='first')
            df = df.sort_values('timestamp').reset_index(drop=True)
        
        cleaned_len = len(df)
        
        if cleaned_len < original_len:
            removed = original_len - cleaned_len
            print(f"âš ï¸ æ•°æ®æ¸…ç†: ç§»é™¤ {removed} æ¡å¼‚å¸¸è®°å½•")
        
        # æ£€æŸ¥æ•°æ®é‡
        if cleaned_len < 100:
            print(f"âŒ æ•°æ®ä¸è¶³: ä»…æœ‰ {cleaned_len} æ¡è®°å½•ï¼Œè‡³å°‘éœ€è¦100æ¡")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½ {cleaned_len} æ¡æ•°æ®")
        
        # æ˜¾ç¤ºæ•°æ®èŒƒå›´ä¿¡æ¯
        if 'timestamp' in df.columns:
            start_time = df['timestamp'].min()
            end_time = df['timestamp'].max()
            print(f"   æ—¶é—´èŒƒå›´: {start_time} ~ {end_time}")
            
            # æ£€æŸ¥æ•°æ®è¿ç»­æ€§
            time_gaps = _check_data_continuity(df, interval)
            if time_gaps > 0:
                print(f"   æ•°æ®é—´éš™: {time_gaps} å¤„")
        
        return df
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def _check_data_continuity(df: pd.DataFrame, interval: str) -> int:
    """æ£€æŸ¥æ•°æ®è¿ç»­æ€§"""
    if len(df) < 2 or 'timestamp' not in df.columns:
        return 0
    
    # è®¡ç®—é¢„æœŸçš„æ—¶é—´é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    interval_minutes = {
        '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
        '1h': 60, '2h': 120, '4h': 240, '6h': 360, '8h': 480, '12h': 720,
        '1d': 1440, '3d': 4320, '1w': 10080, '1M': 43200
    }
    
    expected_minutes = interval_minutes.get(interval, 60)
    expected_delta = pd.Timedelta(minutes=expected_minutes)
    
    # è®¡ç®—æ—¶é—´å·®
    time_diffs = df['timestamp'].diff()[1:]
    
    # å…è®¸çš„è¯¯å·®èŒƒå›´ï¼ˆ10%ï¼‰
    tolerance = expected_delta * 0.1
    min_expected = expected_delta - tolerance
    max_expected = expected_delta + tolerance
    
    # è®¡ç®—é—´éš™æ•°é‡
    gaps = sum((time_diffs < min_expected) | (time_diffs > max_expected))
    
    return gaps

def interactive_select_local_data() -> Tuple[Optional[str], Optional[str]]:
    """äº¤äº’å¼é€‰æ‹©æœ¬åœ°æ•°æ®"""
    print("\nğŸ“ æœ¬åœ°æ•°æ®é€‰æ‹©å™¨")
    print("=" * 50)
    
    local_data = get_local_data_summary()
    
    if not local_data:
        print("âŒ æœªæ‰¾åˆ°æœ¬åœ°æ•°æ®")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. ä½¿ç”¨æ•°æ®ä¸‹è½½å™¨ä¸‹è½½æ•°æ®")
        print("   2. ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜æ”¾åœ¨æ­£ç¡®ä½ç½®:")
        print("      - ç›®å½•ç»“æ„: data/SYMBOL/SYMBOL_INTERVAL.csv")
        print("      - ç¤ºä¾‹: data/BTCUSDT/BTCUSDT_1h.csv")
        print("   3. æ£€æŸ¥æ–‡ä»¶æƒé™å’Œæ ¼å¼")
        return None, None
    
    print(f"ğŸ“Š å‘ç° {len(local_data)} ä¸ªå¸ç§çš„æœ¬åœ°æ•°æ®")
    
    # åˆ›å»ºå¸ç§é€‰æ‹©åˆ—è¡¨
    symbol_choices = []
    for symbol, intervals in local_data.items():
        # æ˜¾ç¤ºå‰3ä¸ªæ—¶é—´å‘¨æœŸï¼Œå¦‚æœæ›´å¤šåˆ™æ˜¾ç¤ºçœç•¥å·
        interval_preview = ', '.join(intervals[:3])
        if len(intervals) > 3:
            interval_preview += f'... (å…±{len(intervals)}ä¸ª)'
        
        symbol_choices.append((f"{symbol:<12} [{interval_preview}]", symbol))
    
    # æŒ‰å¸ç§åç§°æ’åº
    symbol_choices.sort(key=lambda x: x[1])
    
    # é€‰æ‹©å¸ç§
    selected_symbol = safe_list_input("é€‰æ‹©å¸ç§", choices=symbol_choices)
    if selected_symbol is None:
        return None, None
    
    # é€‰æ‹©æ—¶é—´å‘¨æœŸ
    available_intervals = local_data[selected_symbol]
    
    print(f"\nğŸ“Š {selected_symbol} å¯ç”¨æ—¶é—´å‘¨æœŸ:")
    interval_choices = []
    
    for interval in available_intervals:
        # å°è¯•è·å–è¯¥æ—¶é—´å‘¨æœŸçš„æ•°æ®ä¿¡æ¯
        try:
            data = load_local_data(selected_symbol, interval)
            if data is not None:
                data_info = f"({len(data)} æ¡è®°å½•)"
                if 'timestamp' in data.columns:
                    start_time = data['timestamp'].min().strftime('%Y-%m-%d')
                    end_time = data['timestamp'].max().strftime('%Y-%m-%d')
                    data_info += f" [{start_time} ~ {end_time}]"
                
                interval_choices.append((f"{interval:<8} {data_info}", interval))
            else:
                interval_choices.append((f"{interval:<8} (æ•°æ®å¼‚å¸¸)", interval))
        except:
            interval_choices.append((f"{interval:<8} (è¯»å–å¤±è´¥)", interval))
    
    if not interval_choices:
        print(f"âŒ {selected_symbol} æ²¡æœ‰å¯ç”¨çš„æ—¶é—´å‘¨æœŸæ•°æ®")
        return None, None
    
    selected_interval = safe_list_input(f"é€‰æ‹© {selected_symbol} çš„æ—¶é—´å‘¨æœŸ", choices=interval_choices)
    if selected_interval is None:
        return None, None
    
    print(f"âœ… å·²é€‰æ‹©: {selected_symbol} - {selected_interval}")
    return selected_symbol, selected_interval

def validate_data_quality(df: pd.DataFrame, symbol: str, interval: str) -> Dict[str, Any]:
    """éªŒè¯æ•°æ®è´¨é‡"""
    quality_report = {
        'symbol': symbol,
        'interval': interval,
        'total_rows': len(df),
        'issues': [],
        'warnings': [],
        'score': 100  # æ»¡åˆ†100
    }
    
    # æ£€æŸ¥å¿…è¦åˆ—
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        quality_report['issues'].append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        quality_report['score'] -= 30
    
    if quality_report['score'] <= 0:  # å¦‚æœç¼ºå°‘å¿…è¦åˆ—ï¼Œç›´æ¥è¿”å›
        return quality_report
    
    # æ£€æŸ¥ç©ºå€¼
    null_counts = df[required_columns].isnull().sum()
    total_nulls = null_counts.sum()
    
    if total_nulls > 0:
        null_percentage = (total_nulls / (len(df) * len(required_columns))) * 100
        quality_report['warnings'].append(f"ç©ºå€¼: {total_nulls} ä¸ª ({null_percentage:.1f}%)")
        quality_report['score'] -= min(20, null_percentage)
    
    # æ£€æŸ¥OHLCé€»è¾‘é”™è¯¯
    ohlc_errors = 0
    if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
        # Highåº”è¯¥æ˜¯æœ€é«˜ä»·
        ohlc_errors += len(df[(df['high'] < df['open']) | (df['high'] < df['close']) | (df['high'] < df['low'])])
        # Lowåº”è¯¥æ˜¯æœ€ä½ä»·
        ohlc_errors += len(df[(df['low'] > df['open']) | (df['low'] > df['close']) | (df['low'] > df['high'])])
    
    if ohlc_errors > 0:
        error_percentage = (ohlc_errors / len(df)) * 100
        quality_report['issues'].append(f"OHLCé€»è¾‘é”™è¯¯: {ohlc_errors} æ¡ ({error_percentage:.1f}%)")
        quality_report['score'] -= min(25, error_percentage * 2)
    
    # æ£€æŸ¥å¼‚å¸¸ä»·æ ¼ï¼ˆ0æˆ–è´Ÿæ•°ï¼‰
    price_columns = ['open', 'high', 'low', 'close']
    zero_prices = 0
    for col in price_columns:
        if col in df.columns:
            zero_prices += len(df[df[col] <= 0])
    
    if zero_prices > 0:
        zero_percentage = (zero_prices / (len(df) * len(price_columns))) * 100
        quality_report['issues'].append(f"å¼‚å¸¸ä»·æ ¼(â‰¤0): {zero_prices} ä¸ª ({zero_percentage:.1f}%)")
        quality_report['score'] -= min(15, zero_percentage)
    
    # æ£€æŸ¥æ•°æ®è¿ç»­æ€§ï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰
    if 'timestamp' in df.columns:
        gaps = _check_data_continuity(df, interval)
        if gaps > len(df) * 0.05:  # è¶…è¿‡5%çš„é—´éš™
            gap_percentage = (gaps / len(df)) * 100
            quality_report['warnings'].append(f"æ•°æ®é—´éš™: {gaps} å¤„ ({gap_percentage:.1f}%)")
            quality_report['score'] -= min(10, gap_percentage)
    
    # æ£€æŸ¥é‡å¤æ•°æ®
    if 'timestamp' in df.columns:
        duplicates = df.duplicated(subset=['timestamp']).sum()
        if duplicates > 0:
            dup_percentage = (duplicates / len(df)) * 100
            quality_report['warnings'].append(f"é‡å¤æ—¶é—´æˆ³: {duplicates} æ¡ ({dup_percentage:.1f}%)")
            quality_report['score'] -= min(10, dup_percentage)
    
    # ç¡®ä¿å¾—åˆ†ä¸ä½äº0
    quality_report['score'] = max(0, quality_report['score'])
    
    return quality_report

def print_data_quality_report(quality_report: Dict[str, Any]):
    """æ‰“å°æ•°æ®è´¨é‡æŠ¥å‘Š"""
    symbol = quality_report['symbol']
    interval = quality_report['interval']
    score = quality_report['score']
    
    print(f"\nğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š: {symbol} {interval}")
    print("=" * 50)
    print(f"æ€»è®°å½•æ•°: {quality_report['total_rows']:,}")
    print(f"è´¨é‡å¾—åˆ†: {score:.0f}/100", end="")
    
    # æ ¹æ®å¾—åˆ†æ˜¾ç¤ºç­‰çº§
    if score >= 90:
        print(" ğŸŸ¢ ä¼˜ç§€")
    elif score >= 75:
        print(" ğŸŸ¡ è‰¯å¥½")
    elif score >= 60:
        print(" ğŸŸ  ä¸€èˆ¬")
    else:
        print(" ğŸ”´ è¾ƒå·®")
    
    # æ˜¾ç¤ºé—®é¢˜
    if quality_report['issues']:
        print("\nâŒ ä¸¥é‡é—®é¢˜:")
        for issue in quality_report['issues']:
            print(f"   â€¢ {issue}")
    
    # æ˜¾ç¤ºè­¦å‘Š
    if quality_report['warnings']:
        print("\nâš ï¸ è­¦å‘Š:")
        for warning in quality_report['warnings']:
            print(f"   â€¢ {warning}")
    
    if not quality_report['issues'] and not quality_report['warnings']:
        print("\nâœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°é—®é¢˜")
    
    # å»ºè®®
    if score < 75:
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        if score < 60:
            print("   â€¢ è€ƒè™‘é‡æ–°ä¸‹è½½æ•°æ®")
        print("   â€¢ ä½¿ç”¨æ•°æ®æ¸…ç†åŠŸèƒ½")
        print("   â€¢ æ£€æŸ¥æ•°æ®æºè´¨é‡")

def get_data_statistics(df: pd.DataFrame) -> Dict[str, Any]:
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'total_records': len(df),
        'date_range': {},
        'price_stats': {},
        'volume_stats': {},
        'data_quality': {}
    }
    
    # æ—¶é—´èŒƒå›´
    if 'timestamp' in df.columns:
        stats['date_range'] = {
            'start': df['timestamp'].min(),
            'end': df['timestamp'].max(),
            'duration_days': (df['timestamp'].max() - df['timestamp'].min()).days
        }
    
    # ä»·æ ¼ç»Ÿè®¡