#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤æ˜“è®°å½•çˆ¬å–è„šæœ¬ - æ‰‹åŠ¨ç¿»é¡µç‰ˆæœ¬
ç”¨äºè·å–äº¤æ˜“å¹³å°çš„æ‰€æœ‰äº¤æ˜“è®°å½•å¹¶ä¿å­˜ä¸ºCSVæ–‡ä»¶
"""

import csv
import time
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class TradingRecordScraper:
    def __init__(self, url, headless=False):
        """
        åˆå§‹åŒ–çˆ¬è™«
        :param url: ç›®æ ‡ç½‘å€
        :param headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
        """
        self.url = url
        self.driver = None
        self.records = []
        self.setup_driver(headless)
    
    def setup_driver(self, headless):
        """è®¾ç½®WebDriver"""
        chrome_options = Options()
        if headless:
            chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        
        # æ·»åŠ ç”¨æˆ·ä»£ç†
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.wait = WebDriverWait(self.driver, 10)
    
    def get_current_page_number(self):
        """è·å–å½“å‰é¡µç """
        try:
            # æŸ¥æ‰¾å½“å‰æ¿€æ´»çš„é¡µç 
            active_page = self.driver.find_element(By.CSS_SELECTOR, ".bn-pagination-item.active")
            page_text = active_page.text.strip()
            
            if page_text.isdigit():
                return int(page_text)
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾aria-current='page'
            try:
                current_page = self.driver.find_element(By.CSS_SELECTOR, "[aria-current='page']")
                page_text = current_page.text.strip()
                if page_text.isdigit():
                    return int(page_text)
            except:
                pass
                
            return 1  # é»˜è®¤ç¬¬1é¡µ
        except Exception as e:
            print(f"âš ï¸ è·å–å½“å‰é¡µç å¤±è´¥: {e}")
            return 1
    
    def get_total_pages(self):
        """è·å–æ€»é¡µæ•°"""
        try:
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªé¡µç æŒ‰é’®
            page_buttons = self.driver.find_elements(By.CSS_SELECTOR, ".bn-pagination-item")
            
            max_page = 1
            for btn in page_buttons:
                btn_text = btn.text.strip()
                if btn_text.isdigit():
                    max_page = max(max_page, int(btn_text))
            
            # ä¹Ÿå¯ä»¥æŸ¥æ‰¾"84"è¿™æ ·çš„æœ€å¤§é¡µç 
            if max_page == 1:
                # å°è¯•æŸ¥æ‰¾åŒ…å«æ•°å­—çš„æ–‡æœ¬
                page_info_elements = self.driver.find_elements(By.CSS_SELECTOR, "*")
                for element in page_info_elements:
                    text = element.text.strip()
                    # æŸ¥æ‰¾ç±»ä¼¼"ç¬¬1é¡µï¼Œå…±84é¡µ"çš„æ–‡æœ¬
                    match = re.search(r'å…±\s*(\d+)\s*é¡µ', text)
                    if match:
                        return int(match.group(1))
                    
                    # æŸ¥æ‰¾é¡µç åºåˆ—ï¼Œæ‰¾æœ€å¤§çš„æ•°å­—
                    if re.match(r'^\d+$', text) and len(text) <= 3:
                        try:
                            page_num = int(text)
                            if 50 <= page_num <= 999:  # å‡è®¾æ€»é¡µæ•°åœ¨è¿™ä¸ªèŒƒå›´
                                max_page = max(max_page, page_num)
                        except:
                            pass
            
            return max_page if max_page > 1 else 84  # é»˜è®¤84é¡µï¼ˆä»æˆªå›¾çœ‹åˆ°çš„ï¼‰
            
        except Exception as e:
            print(f"âš ï¸ è·å–æ€»é¡µæ•°å¤±è´¥: {e}")
            return 84  # é»˜è®¤å€¼
    
    def wait_for_page_change(self, current_page, timeout=300):
        """
        ç­‰å¾…é¡µé¢å˜åŒ–ï¼ˆç”¨æˆ·æ‰‹åŠ¨ç¿»é¡µï¼‰
        :param current_page: å½“å‰é¡µç 
        :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        :return: æ–°çš„é¡µç ï¼Œå¦‚æœè¶…æ—¶è¿”å›None
        """
        print(f"\nâ³ ç­‰å¾…é¡µé¢å˜åŒ–...")
        print(f"ğŸ“– å½“å‰é¡µ: {current_page}")
        print(f"ğŸ–±ï¸  è¯·æ‰‹åŠ¨ç‚¹å‡»ç¿»é¡µæŒ‰é’®...")
        print(f"â° ç¨‹åºå°†è‡ªåŠ¨æ£€æµ‹é¡µé¢å˜åŒ–ï¼ˆè¶…æ—¶æ—¶é—´: {timeout}ç§’ï¼‰")
        print(f"ğŸ’¡ å¦‚æœå·²æ˜¯æœ€åä¸€é¡µï¼Œè¯·ç­‰å¾…ç¨‹åºè‡ªåŠ¨é€€å‡ºï¼Œæˆ–æŒ‰ Ctrl+C åœæ­¢")
        
        start_time = time.time()
        check_interval = 1  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        
        while time.time() - start_time < timeout:
            try:
                # æ£€æŸ¥é¡µç æ˜¯å¦å˜åŒ–
                new_page = self.get_current_page_number()
                
                if new_page != current_page:
                    print(f"âœ… æ£€æµ‹åˆ°é¡µé¢å˜åŒ–: {current_page} â†’ {new_page}")
                    # ç­‰å¾…æ•°æ®åŠ è½½å®Œæˆ
                    time.sleep(3)
                    return new_page
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µæŒ‰é’®å¯ç”¨
                try:
                    next_buttons = self.driver.find_elements(By.CSS_SELECTOR, 
                        ".bn-pagination-item:not(.disabled):last-child")
                    if not next_buttons:
                        print("â„¹ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                        return None
                except:
                    pass
                
                time.sleep(check_interval)
                
                # æ¯30ç§’æç¤ºä¸€æ¬¡
                elapsed = time.time() - start_time
                if int(elapsed) % 30 == 0 and int(elapsed) > 0:
                    remaining = timeout - elapsed
                    print(f"â³ ä»åœ¨ç­‰å¾…ç¿»é¡µ... (å‰©ä½™ {int(remaining)} ç§’)")
                
            except KeyboardInterrupt:
                print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç­‰å¾…")
                return None
            except Exception as e:
                print(f"âš ï¸ æ£€æµ‹é¡µé¢å˜åŒ–æ—¶å‡ºé”™: {e}")
                time.sleep(check_interval)
        
        print(f"â° ç­‰å¾…è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œåœæ­¢æ£€æµ‹")
        return None
    
    def extract_record_from_row(self, row_element):
        """
        ä»è¡¨æ ¼è¡Œå…ƒç´ ä¸­æå–äº¤æ˜“è®°å½•
        :param row_element: è¡¨æ ¼è¡Œå…ƒç´ 
        :return: äº¤æ˜“è®°å½•å­—å…¸
        """
        try:
            # è¿™ç§è¡¨æ ¼ç»“æ„ï¼šæ¯è¡Œåªæœ‰ä¸€ä¸ªå¤§çš„tdï¼Œæ•°æ®åœ¨å†…éƒ¨divä¸­ç»„ç»‡
            
            # 1. æå–äº¤æ˜“å¯¹ç¬¦å·
            symbol = ""
            try:
                symbol_element = row_element.find_element(By.CSS_SELECTOR, ".t-subtitle1.text-PrimaryText")
                symbol = symbol_element.text.strip()
            except:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä»æ–‡æœ¬ä¸­æå–
                row_text = row_element.text
                symbol_match = re.search(r'([A-Z]+USDT?)', row_text)
                symbol = symbol_match.group(1) if symbol_match else "UNKNOWN"
            
            # 2. æå–äº¤æ˜“æ–¹å‘
            direction = "Long"  # é»˜è®¤åšå¤š
            try:
                # æŸ¥æ‰¾åšå¤š/åšç©ºæ ‡ç­¾
                direction_element = row_element.find_element(By.CSS_SELECTOR, ".bn-bubble__success .bn-bubble-content")
                direction_text = direction_element.text.strip()
                if "åšç©º" in direction_text or "ç©º" in direction_text:
                    direction = "Short"
                elif "åšå¤š" in direction_text or "å¤š" in direction_text:
                    direction = "Long"
            except:
                pass
            
            # 3. æå–å„ä¸ªæ•°æ®å­—æ®µ - ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            data_fields = {}
            
            # è·å–æ‰€æœ‰æ•°æ®å®¹å™¨
            data_containers = row_element.find_elements(By.CSS_SELECTOR, ".w-\\[calc\\(20\\%-13px\\)\\]")
            
            for container in data_containers:
                try:
                    # è·å–å­—æ®µæ ‡é¢˜å’Œå€¼
                    label_element = container.find_element(By.CSS_SELECTOR, ".t-caption2.text-SecondaryText")
                    value_element = container.find_element(By.CSS_SELECTOR, ".t-caption2.text-PrimaryText")
                    
                    label = label_element.text.strip()
                    value = value_element.text.strip()
                    
                    if label and value:
                        data_fields[label] = value
                        
                except:
                    continue
            
            # 4. ä»æ•°æ®å­—æ®µä¸­æå–å…·ä½“ä¿¡æ¯
            entry_time = data_fields.get('å¼€ä»“æ—¶é—´', '')
            entry_price = self.extract_number(data_fields.get('å¼€ä»“ä»·æ ¼', ''))
            max_position = self.extract_number(data_fields.get('æœ€å¤§æŒä»“é‡', ''))
            exit_time = data_fields.get('å…¨éƒ¨å¹³ä»“', '')
            exit_price = self.extract_number(data_fields.get('å¹³ä»“å‡ä»·', ''))
            
            # 5. æå–ç›ˆäºä¿¡æ¯
            profit_loss = ""
            try:
                profit_element = row_element.find_element(By.CSS_SELECTOR, ".text-Buy, .text-Sell")
                profit_loss = profit_element.text.strip()
            except:
                profit_loss = data_fields.get('å¹³ä»“ç›ˆäº', '')
            
            profit_loss = self.extract_profit_loss(profit_loss)
            
            # 6. è®¡ç®—æŒä»“æ—¶é•¿
            hold_duration = self.calculate_duration(entry_time, exit_time)
            
            # 7. è®¡ç®—ç›ˆäºç™¾åˆ†æ¯”
            profit_pct = self.calculate_profit_percentage(profit_loss, entry_price, max_position)
            
            record = {
                'symbol': symbol,
                'interval': '1d',
                'entry_time': entry_time,
                'exit_time': exit_time,
                'entry_price': entry_price,
                'exit_price': exit_price,
                'direction': direction,
                'profit_loss': profit_loss,
                'profit_pct': profit_pct,
                'hold_duration': hold_duration,
                'exit_reason': 'Manual'
            }
            
            return record
            
        except Exception as e:
            print(f"æå–è®°å½•æ—¶å‡ºé”™: {e}")
            return None
    
    def parse_datetime(self, datetime_str):
        """è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
        if not datetime_str:
            return ''
        
        try:
            # åŒ¹é…æ ¼å¼ï¼š2025-05-22 06:56:53
            if re.match(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', datetime_str):
                return datetime_str
            
            # å…¶ä»–å¯èƒ½çš„æ—¥æœŸæ ¼å¼å¤„ç†
            return datetime_str
        except:
            return datetime_str
    
    def extract_number(self, text):
        """ä»æ–‡æœ¬ä¸­æå–æ•°å­—"""
        if not text:
            return ''
        
        # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼Œä¿ç•™å°æ•°ç‚¹
        number_match = re.search(r'[\d,]+\.?\d*', text.replace(',', ''))
        return number_match.group() if number_match else ''
    
    def extract_profit_loss(self, text):
        """æå–ç›ˆäºæ•°å€¼"""
        if not text:
            return ''
        
        # åŒ¹é…åŒ…å«æ­£è´Ÿå·çš„æ•°å­—
        profit_match = re.search(r'[+-]?[\d,]+\.?\d*', text)
        return profit_match.group() if profit_match else ''
    
    def determine_direction(self, row_element, profit_loss):
        """æ ¹æ®è¡Œæ ·å¼æˆ–ç›ˆäºåˆ¤æ–­äº¤æ˜“æ–¹å‘"""
        try:
            # æ£€æŸ¥ç›ˆäºæ–‡æœ¬çš„é¢œè‰²
            profit_element = row_element.find_elements(By.CSS_SELECTOR, "[style*='color']")
            
            if profit_loss and isinstance(profit_loss, str):
                if profit_loss.startswith('+'):
                    return 'Long'
                elif profit_loss.startswith('-'):
                    return 'Short'
            
            # é»˜è®¤è¿”å›
            return 'Long'
        except:
            return 'Long'
    
    def calculate_duration(self, entry_time, exit_time):
        """è®¡ç®—æŒä»“æ—¶é•¿"""
        if not entry_time or not exit_time:
            return ''
        
        try:
            entry_dt = datetime.strptime(entry_time, '%Y-%m-%d %H:%M:%S')
            exit_dt = datetime.strptime(exit_time, '%Y-%m-%d %H:%M:%S')
            duration = exit_dt - entry_dt
            
            days = duration.days
            hours, remainder = divmod(duration.seconds, 3600)
            minutes, _ = divmod(remainder, 60)
            
            if days > 0:
                return f"{days}d {hours}h {minutes}m"
            elif hours > 0:
                return f"{hours}h {minutes}m"
            else:
                return f"{minutes}m"
        except:
            return ''
    
    def calculate_profit_percentage(self, profit_loss, entry_price, position_size):
        """è®¡ç®—ç›ˆäºç™¾åˆ†æ¯”"""
        try:
            if not all([profit_loss, entry_price, position_size]):
                return ''
            
            profit_num = float(str(profit_loss).replace('+', '').replace(',', ''))
            entry_num = float(str(entry_price).replace(',', ''))
            position_num = float(str(position_size).replace(',', ''))
            
            if entry_num > 0 and position_num > 0:
                invested = entry_num * position_num
                pct = (profit_num / invested) * 100
                return f"{pct:.2f}%"
        except:
            pass
        
        return ''
    
    def scrape_current_page(self):
        """çˆ¬å–å½“å‰é¡µé¢çš„äº¤æ˜“è®°å½•"""
        try:
            print("â³ ç­‰å¾…é¡µé¢æ•°æ®åŠ è½½...")
            # ç­‰å¾…è¡¨æ ¼è¡ŒåŠ è½½
            self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "tr.bn-web-table-row"))
            )
            
            # é¢å¤–ç­‰å¾…ç¡®ä¿æ•°æ®å®Œå…¨åŠ è½½
            time.sleep(2)
            
            # è·å–æ‰€æœ‰æ•°æ®è¡Œ
            rows = self.driver.find_elements(By.CSS_SELECTOR, "tr.bn-web-table-row")
            print(f"ğŸ“Š æ‰¾åˆ° {len(rows)} è¡Œæ•°æ®")
            
            if not rows:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®è¡Œ")
                return []
            
            page_records = []
            
            # é€è¡Œå¤„ç†
            for i, row in enumerate(rows):
                try:
                    # æ£€æŸ¥è¡Œæ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
                    row_text = row.text.strip()
                    if not row_text or len(row_text) < 10:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«äº¤æ˜“å¯¹ä¿¡æ¯
                    if not re.search(r'[A-Z]+USDT?', row_text):
                        continue
                    
                    record = self.extract_record_from_row(row)
                    if record:
                        page_records.append(record)
                        print(f"âœ… è®°å½• {i+1}: {record['symbol']} | {record['direction']} | ç›ˆäº: {record['profit_loss']}")
                        
                except Exception as e:
                    print(f"âŒ å¤„ç†ç¬¬ {i+1} è¡Œæ—¶å‡ºé”™: {e}")
                    continue
            
            print(f"ğŸ“‹ æœ¬é¡µå…±æå–åˆ° {len(page_records)} æ¡æœ‰æ•ˆè®°å½•")
            return page_records
            
        except TimeoutException:
            print("â° é¡µé¢åŠ è½½è¶…æ—¶")
            return []
        except Exception as e:
            print(f"âŒ çˆ¬å–å½“å‰é¡µé¢æ—¶å‡ºé”™: {e}")
            return []
    
    def scrape_all_pages_manual(self):
        """æ‰‹åŠ¨ç¿»é¡µæ¨¡å¼ï¼šçˆ¬å–æ‰€æœ‰é¡µé¢çš„äº¤æ˜“è®°å½•"""
        print("ğŸš€ å¼€å§‹æ‰‹åŠ¨ç¿»é¡µæ¨¡å¼çˆ¬å–äº¤æ˜“è®°å½•...")
        print("ğŸ“– ç¨‹åºå°†æ£€æµ‹é¡µé¢å˜åŒ–ï¼Œè¯·æ‰‹åŠ¨ç‚¹å‡»ç¿»é¡µæŒ‰é’®")
        
        # æ‰“å¼€ç½‘é¡µ
        self.driver.get(self.url)
        time.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        
        # è·å–æ€»é¡µæ•°å’Œå½“å‰é¡µ
        total_pages = self.get_total_pages()
        current_page = self.get_current_page_number()
        
        print(f"ğŸ“„ æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
        print(f"ğŸ“– å½“å‰é¡µç : {current_page}")
        
        total_records = 0
        
        while current_page <= total_pages:
            print(f"\n" + "="*60)
            print(f"ğŸ“– æ­£åœ¨å¤„ç†ç¬¬ {current_page} é¡µ (å…± {total_pages} é¡µ)")
            print(f"ğŸ“Š å·²æ”¶é›†è®°å½•: {total_records} æ¡")
            print("="*60)
            
            # çˆ¬å–å½“å‰é¡µé¢
            page_records = self.scrape_current_page()
            
            if page_records:
                self.records.extend(page_records)
                total_records += len(page_records)
                print(f"âœ… ç¬¬ {current_page} é¡µè·å–åˆ° {len(page_records)} æ¡è®°å½•")
                
                # ä¿å­˜ä¸­é—´ç»“æœï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰
                if total_records % 50 == 0:  # æ¯50æ¡è®°å½•ä¿å­˜ä¸€æ¬¡
                    self.save_to_csv(f'trade_records_backup_{total_records}.csv')
                    print(f"ğŸ’¾ å·²ä¿å­˜å¤‡ä»½æ–‡ä»¶ï¼ˆ{total_records}æ¡è®°å½•ï¼‰")
            else:
                print(f"âš ï¸ ç¬¬ {current_page} é¡µæ²¡æœ‰æ‰¾åˆ°è®°å½•")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€åä¸€é¡µ
            if current_page >= total_pages:
                print(f"ğŸ‰ å·²å¤„ç†å®Œæ‰€æœ‰é¡µé¢ï¼ˆç¬¬ {total_pages} é¡µï¼‰")
                break
            
            # ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç¿»é¡µ
            print(f"\nğŸ’¡ è¯·æ‰‹åŠ¨ç‚¹å‡»ç¿»é¡µæŒ‰é’®ï¼Œè·³è½¬åˆ°ç¬¬ {current_page + 1} é¡µ")
            new_page = self.wait_for_page_change(current_page, timeout=300)
            
            if new_page is None:
                print("â¹ï¸ æœªæ£€æµ‹åˆ°é¡µé¢å˜åŒ–ï¼Œåœæ­¢çˆ¬å–")
                break
            elif new_page <= current_page:
                print(f"âš ï¸ é¡µç æ²¡æœ‰å¢åŠ ï¼ˆ{current_page} â†’ {new_page}ï¼‰ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                break
            else:
                current_page = new_page
                print(f"âœ… é¡µé¢å·²æ›´æ–°åˆ°ç¬¬ {current_page} é¡µï¼Œç»§ç»­æŠ“å–...")
        
        print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±è·å–åˆ° {total_records} æ¡äº¤æ˜“è®°å½•")
        print(f"ğŸ“„ å¤„ç†äº† {current_page} é¡µæ•°æ®")
        
        return self.records
    
    def save_to_csv(self, filename='trade_records.csv'):
        """ä¿å­˜è®°å½•åˆ°CSVæ–‡ä»¶"""
        if not self.records:
            print("æ²¡æœ‰è®°å½•éœ€è¦ä¿å­˜")
            return
        
        fieldnames = [
            'symbol', 'interval', 'entry_time', 'exit_time', 
            'entry_price', 'exit_price', 'direction', 'profit_loss', 
            'profit_pct', 'hold_duration', 'exit_reason'
        ]
        
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.records)
        
        print(f"ğŸ’¾ è®°å½•å·²ä¿å­˜åˆ° {filename}")
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ äº¤æ˜“è®°å½•çˆ¬å–å·¥å…· - æ‰‹åŠ¨ç¿»é¡µç‰ˆ")
    print("="*60)
    
    # è·å–ç½‘å€
    url = input("è¯·è¾“å…¥äº¤æ˜“å¹³å°çš„ç½‘å€: ").strip()
    
    if not url:
        print("âŒ è¯·æä¾›æœ‰æ•ˆçš„ç½‘å€")
        return
    
    # è¯¢é—®æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
    headless_input = input("æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
    headless = headless_input in ['y', 'yes', 'æ˜¯']
    
    if headless:
        print("âš ï¸ æ³¨æ„ï¼šæ— å¤´æ¨¡å¼ä¸‹æ— æ³•æ‰‹åŠ¨ç¿»é¡µï¼Œå»ºè®®ä½¿ç”¨å¯è§†æ¨¡å¼")
        confirm = input("ç¡®å®šä½¿ç”¨æ— å¤´æ¨¡å¼å—ï¼Ÿ(y/n): ").strip().lower()
        if confirm not in ['y', 'yes', 'æ˜¯']:
            headless = False
    
    scraper = TradingRecordScraper(url, headless=headless)
    
    try:
        print("\nğŸš€ å¼€å§‹è¿è¡Œ...")
        print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
        print("   1. ç¨‹åºä¼šè‡ªåŠ¨åˆ†æé¡µé¢ç»“æ„")
        print("   2. æŠ“å–å½“å‰é¡µæ•°æ®åï¼Œç¨‹åºä¼šæç¤ºæ‚¨æ‰‹åŠ¨ç¿»é¡µ")
        print("   3. ç¨‹åºæ£€æµ‹åˆ°é¡µé¢å˜åŒ–åä¼šè‡ªåŠ¨ç»§ç»­æŠ“å–")
        print("   4. é‡å¤æ­¤è¿‡ç¨‹ç›´åˆ°æ‰€æœ‰é¡µé¢å®Œæˆ")
        print("   5. æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢ç¨‹åº")
        
        # ä½¿ç”¨æ‰‹åŠ¨ç¿»é¡µæ¨¡å¼
        scraper.scrape_all_pages_manual()
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        if scraper.records:
            scraper.save_to_csv('trade_records_final.csv')
            print(f"\nâœ… æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ° trade_records_final.csv")
            print(f"ğŸ“Š æ€»è®¡ {len(scraper.records)} æ¡äº¤æ˜“è®°å½•")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•äº¤æ˜“è®°å½•")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        if scraper.records:
            scraper.save_to_csv('trade_records_interrupted.csv')
            print(f"ğŸ’¾ å·²ä¿å­˜ä¸­æ–­å‰çš„æ•°æ®åˆ° trade_records_interrupted.csv")
            print(f"ğŸ“Š å…± {len(scraper.records)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        if scraper.records:
            scraper.save_to_csv('trade_records_error.csv')
            print(f"ğŸ’¾ å·²ä¿å­˜å‡ºé”™å‰çš„æ•°æ®åˆ° trade_records_error.csv")
    finally:
        scraper.close()
        print("\nğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main()