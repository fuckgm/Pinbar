#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡è®­ç»ƒæ•°æ®ç³»ç»Ÿ
é€šè¿‡å†å²äº¤æ˜“è®°å½•æ‰¹é‡è®­ç»ƒï¼Œä¼˜åŒ–ç­–ç•¥å‚æ•°
"""

import pandas as pd
import numpy as np
import pickle
import json
import os
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import concurrent.futures
from pathlib import Path

try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.metrics import mean_squared_error, r2_score
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

@dataclass
class TradeRecord:
    """äº¤æ˜“è®°å½•æ•°æ®ç»“æ„"""
    trade_id: str
    symbol: str
    interval: str
    entry_time: str
    exit_time: str
    entry_price: float
    exit_price: float
    direction: str  # 'buy' or 'sell'
    profit_loss: float
    profit_pct: float
    hold_duration: int  # æŒä»“Kçº¿æ•°é‡
    max_favorable: float  # æœ€å¤§æœ‰åˆ©ä»·æ ¼
    max_adverse: float   # æœ€å¤§ä¸åˆ©ä»·æ ¼
    exit_reason: str
    
    # ç­–ç•¥ç›¸å…³
    signal_strength: int
    confidence_score: float
    trend_alignment: bool
    volume_confirmation: bool
    
    # å¸‚åœºç¯å¢ƒ
    market_volatility: float
    trend_strength: float
    
    def to_dict(self):
        return asdict(self)

@dataclass
class BatchTrainingConfig:
    """æ‰¹é‡è®­ç»ƒé…ç½®"""
    # æ•°æ®è·¯å¾„
    data_directory: str = "data/"
    trade_records_file: str = "trade_records.json"
    model_output_dir: str = "models/batch/"
    
    # è®­ç»ƒå‚æ•°
    min_samples_per_symbol: int = 100
    test_size: float = 0.2
    cv_folds: int = 5
    
    # ç‰¹å¾å·¥ç¨‹
    lookback_periods: List[int] = None
    feature_groups: List[str] = None
    
    # å¹¶è¡Œå¤„ç†
    max_workers: int = 4
    
    def __post_init__(self):
        if self.lookback_periods is None:
            self.lookback_periods = [5, 10, 20, 50]
        if self.feature_groups is None:
            self.feature_groups = ['price', 'technical', 'volume', 'volatility', 'pattern']

class BatchTrainingSystem:
    """æ‰¹é‡è®­ç»ƒæ•°æ®ç³»ç»Ÿ"""
    
    def __init__(self, config: BatchTrainingConfig = None):
        if not ML_AVAILABLE:
            raise ImportError("æœºå™¨å­¦ä¹ æ¨¡å—æœªå®‰è£…")
        
        self.config = config or BatchTrainingConfig()
        self.trained_models = {}
        self.feature_importance = {}
        self.performance_metrics = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config.model_output_dir, exist_ok=True)
    
    def prepare_batch_training_data(self, trade_records: List[TradeRecord], 
                                  symbols: List[str] = None) -> Dict[str, pd.DataFrame]:
        """å‡†å¤‡æ‰¹é‡è®­ç»ƒæ•°æ®"""
        
        print("ğŸ”§ å‡†å¤‡æ‰¹é‡è®­ç»ƒæ•°æ®...")
        
        if symbols is None:
            symbols = list(set(record.symbol for record in trade_records))
        
        batch_data = {}
        
        for symbol in symbols:
            print(f"ğŸ“Š å¤„ç† {symbol} æ•°æ®...")
            
            # è¿‡æ»¤è¯¥å¸ç§çš„äº¤æ˜“è®°å½•
            symbol_records = [r for r in trade_records if r.symbol == symbol]
            
            if len(symbol_records) < self.config.min_samples_per_symbol:
                print(f"âš ï¸  {symbol} æ ·æœ¬ä¸è¶³ ({len(symbol_records)} < {self.config.min_samples_per_symbol})")
                continue
            
            try:
                # ä¸ºæ¯ä¸ªå¸ç§å‡†å¤‡è®­ç»ƒæ•°æ®
                symbol_data = self._prepare_symbol_data(symbol, symbol_records)
                if symbol_data is not None and len(symbol_data) > 0:
                    batch_data[symbol] = symbol_data
                    print(f"âœ… {symbol} æ•°æ®å‡†å¤‡å®Œæˆ: {len(symbol_data)} æ ·æœ¬")
                
            except Exception as e:
                print(f"âŒ {symbol} æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
                continue
        
        print(f"ğŸ“Š æ‰¹é‡æ•°æ®å‡†å¤‡å®Œæˆ: {len(batch_data)} ä¸ªå¸ç§")
        return batch_data
    
    def _prepare_symbol_data(self, symbol: str, trade_records: List[TradeRecord]) -> Optional[pd.DataFrame]:
        """ä¸ºå•ä¸ªå¸ç§å‡†å¤‡è®­ç»ƒæ•°æ®"""
        
        # åŠ è½½Kçº¿æ•°æ®
        intervals = list(set(record.interval for record in trade_records))
        
        combined_data = []
        
        for interval in intervals:
            interval_records = [r for r in trade_records if r.interval == interval]
            
            try:
                # åŠ è½½Kçº¿æ•°æ®
                from data_utils import load_local_data
                kline_data = load_local_data(symbol, interval)
                
                if kline_data is None:
                    continue
                
                # ä¸ºæ¯ä¸ªäº¤æ˜“è®°å½•åˆ›å»ºè®­ç»ƒæ ·æœ¬
                for record in interval_records:
                    sample = self._create_training_sample(kline_data, record)
                    if sample is not None:
                        combined_data.append(sample)
                        
            except Exception as e:
                print(f"âŒ {symbol} {interval} æ•°æ®å¤„ç†å¤±è´¥: {e}")
                continue
        
        if not combined_data:
            return None
        
        # åˆå¹¶æ‰€æœ‰æ ·æœ¬
        result_df = pd.DataFrame(combined_data)
        return result_df
    
    def _create_training_sample(self, kline_data: pd.DataFrame, 
                              trade_record: TradeRecord) -> Optional[Dict[str, Any]]:
        """æ ¹æ®äº¤æ˜“è®°å½•åˆ›å»ºè®­ç»ƒæ ·æœ¬"""
        
        try:
            # æ‰¾åˆ°å…¥åœºæ—¶é—´å¯¹åº”çš„Kçº¿ç´¢å¼•
            entry_time = pd.to_datetime(trade_record.entry_time)
            kline_data['timestamp'] = pd.to_datetime(kline_data['timestamp'])
            
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„Kçº¿
            time_diff = (kline_data['timestamp'] - entry_time).abs()
            entry_idx = time_diff.idxmin()
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
            lookback = max(self.config.lookback_periods)
            if entry_idx < lookback:
                return None
            
            # æå–å…¥åœºå‰çš„Kçº¿æ•°æ®ç”¨äºç‰¹å¾å·¥ç¨‹
            feature_data = kline_data.iloc[entry_idx-lookback:entry_idx+1].copy()
            
            # æå–ç‰¹å¾
            features = self._extract_comprehensive_features(feature_data, trade_record)
            
            # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆå¤šä¸ªä¼˜åŒ–ç›®æ ‡ï¼‰
            targets = self._create_optimization_targets(trade_record)
            
            # åˆå¹¶ç‰¹å¾å’Œç›®æ ‡
            sample = {**features, **targets}
            
            # æ·»åŠ å…ƒæ•°æ®
            sample.update({
                'symbol': trade_record.symbol,
                'interval': trade_record.interval,
                'entry_time': trade_record.entry_time,
                'trade_id': trade_record.trade_id
            })
            
            return sample
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè®­ç»ƒæ ·æœ¬å¤±è´¥: {e}")
            return None
    
    def _extract_comprehensive_features(self, kline_data: pd.DataFrame, 
                                      trade_record: TradeRecord) -> Dict[str, float]:
        """æå–ç»¼åˆç‰¹å¾"""
        
        features = {}
        
        # 1. ä»·æ ¼ç‰¹å¾
        if 'price' in self.config.feature_groups:
            features.update(self._extract_price_features(kline_data))
        
        # 2. æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        if 'technical' in self.config.feature_groups:
            features.update(self._extract_technical_features(kline_data))
        
        # 3. æˆäº¤é‡ç‰¹å¾
        if 'volume' in self.config.feature_groups:
            features.update(self._extract_volume_features(kline_data))
        
        # 4. æ³¢åŠ¨ç‡ç‰¹å¾
        if 'volatility' in self.config.feature_groups:
            features.update(self._extract_volatility_features(kline_data))
        
        # 5. å½¢æ€ç‰¹å¾
        if 'pattern' in self.config.feature_groups:
            features.update(self._extract_pattern_features(kline_data))
        
        # 6. äº¤æ˜“ä¿¡å·ç‰¹å¾ï¼ˆä»åŸå§‹ä¿¡å·ï¼‰
        features.update({
            'original_signal_strength': trade_record.signal_strength,
            'original_confidence_score': trade_record.confidence_score,
            'original_trend_alignment': float(trade_record.trend_alignment),
            'original_volume_confirmation': float(trade_record.volume_confirmation),
        })
        
        return features
    
    def _extract_price_features(self, data: pd.DataFrame) -> Dict[str, float]:
        """æå–ä»·æ ¼ç‰¹å¾"""
        features = {}
        close = data['close']
        high = data['high'] 
        low = data['low']
        
        # å¤šå‘¨æœŸæ”¶ç›Šç‡
        for period in self.config.lookback_periods:
            if len(close) > period:
                features[f'return_{period}d'] = close.iloc[-1] / close.iloc[-period-1] - 1
                features[f'volatility_{period}d'] = close.pct_change().tail(period).std()
        
        # ä»·æ ¼ä½ç½®ç‰¹å¾
        for period in [10, 20, 50]:
            if len(close) > period:
                rolling_high = high.tail(period).max()
                rolling_low = low.tail(period).min()
                if rolling_high > rolling_low:
                    features[f'price_position_{period}d'] = (close.iloc[-1] - rolling_low) / (rolling_high - rolling_low)
        
        return features
    
    def _extract_technical_features(self, data: pd.DataFrame) -> Dict[str, float]:
        """æå–æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
        import talib
        
        features = {}
        close = data['close'].values
        high = data['high'].values
        low = data['low'].values
        
        # RSI
        rsi = talib.RSI(close, 14)
        if len(rsi) > 0 and not np.isnan(rsi[-1]):
            features['rsi'] = rsi[-1]
        
        # MACD
        macd, signal, hist = talib.MACD(close)
        if len(macd) > 0 and not np.isnan(macd[-1]):
            features['macd'] = macd[-1]
            features['macd_signal'] = signal[-1] if not np.isnan(signal[-1]) else 0
        
        # ADX
        adx = talib.ADX(high, low, close, 14)
        if len(adx) > 0 and not np.isnan(adx[-1]):
            features['adx'] = adx[-1]
        
        # å¸ƒæ—å¸¦
        upper, middle, lower = talib.BBANDS(close)
        if len(upper) > 0 and not np.isnan(upper[-1]):
            bb_width = upper[-1] - lower[-1]
            if bb_width > 0:
                features['bb_position'] = (close[-1] - lower[-1]) / bb_width
                features['bb_width'] = bb_width / middle[-1]
        
        return features
    
    def _extract_volume_features(self, data: pd.DataFrame) -> Dict[str, float]:
        """æå–æˆäº¤é‡ç‰¹å¾"""
        features = {}
        
        if 'volume' in data.columns:
            volume = data['volume']
            
            # æˆäº¤é‡æ¯”ç‡
            for period in [5, 10, 20]:
                if len(volume) > period:
                    avg_volume = volume.tail(period).mean()
                    if avg_volume > 0:
                        features[f'volume_ratio_{period}d'] = volume.iloc[-1] / avg_volume
        
        return features
    
    def _extract_volatility_features(self, data: pd.DataFrame) -> Dict[str, float]:
        """æå–æ³¢åŠ¨ç‡ç‰¹å¾"""
        import talib
        
        features = {}
        high = data['high'].values
        low = data['low'].values
        close = data['close'].values
        
        # ATR
        atr = talib.ATR(high, low, close, 14)
        if len(atr) > 0 and not np.isnan(atr[-1]):
            features['atr'] = atr[-1]
            features['atr_ratio'] = atr[-1] / close[-1]
        
        return features
    
    def _extract_pattern_features(self, data: pd.DataFrame) -> Dict[str, float]:
        """æå–å½¢æ€ç‰¹å¾"""
        import talib
        
        features = {}
        open_price = data['open'].values
        high = data['high'].values
        low = data['low'].values  
        close = data['close'].values
        
        # å¸¸è§å½¢æ€
        patterns = {
            'doji': talib.CDLDOJI(open_price, high, low, close),
            'hammer': talib.CDLHAMMER(open_price, high, low, close),
            'shooting_star': talib.CDLSHOOTINGSTAR(open_price, high, low, close),
        }
        
        for pattern_name, pattern_values in patterns.items():
            if len(pattern_values) > 0:
                features[f'pattern_{pattern_name}'] = float(pattern_values[-1] != 0)
        
        return features
    
    def _create_optimization_targets(self, trade_record: TradeRecord) -> Dict[str, float]:
        """åˆ›å»ºä¼˜åŒ–ç›®æ ‡å˜é‡"""
        
        targets = {
            # ä¸»è¦ç›®æ ‡ï¼šç›ˆåˆ©ç‡
            'profit_pct': trade_record.profit_pct,
            
            # é£é™©è°ƒæ•´æ”¶ç›Š
            'risk_adjusted_return': self._calculate_risk_adjusted_return(trade_record),
            
            # æŒä»“æ•ˆç‡
            'holding_efficiency': self._calculate_holding_efficiency(trade_record),
            
            # é€€å‡ºæ—¶æœºè¯„åˆ†
            'exit_timing_score': self._calculate_exit_timing_score(trade_record),
            
            # åˆ†ç±»ç›®æ ‡ï¼šäº¤æ˜“è´¨é‡
            'trade_quality': self._classify_trade_quality(trade_record),
        }
        
        return targets
    
    def _calculate_risk_adjusted_return(self, trade_record: TradeRecord) -> float:
        """è®¡ç®—é£é™©è°ƒæ•´æ”¶ç›Š"""
        if trade_record.max_adverse == 0:
            return trade_record.profit_pct
        
        max_risk = abs(trade_record.max_adverse - trade_record.entry_price) / trade_record.entry_price
        if max_risk == 0:
            return trade_record.profit_pct
        
        return trade_record.profit_pct / max_risk
    
    def _calculate_holding_efficiency(self, trade_record: TradeRecord) -> float:
        """è®¡ç®—æŒä»“æ•ˆç‡"""
        if trade_record.hold_duration == 0:
            return 0
        
        # æ¯å•ä½æ—¶é—´çš„æ”¶ç›Š
        return trade_record.profit_pct / trade_record.hold_duration
    
    def _calculate_exit_timing_score(self, trade_record: TradeRecord) -> float:
        """è®¡ç®—é€€å‡ºæ—¶æœºè¯„åˆ†"""
        if trade_record.direction == 'buy':
            max_possible = trade_record.max_favorable - trade_record.entry_price
        else:
            max_possible = trade_record.entry_price - trade_record.max_favorable
        
        actual_profit = trade_record.exit_price - trade_record.entry_price
        if trade_record.direction == 'sell':
            actual_profit = -actual_profit
        
        if max_possible <= 0:
            return 0 if actual_profit <= 0 else 1
        
        return actual_profit / max_possible
    
    def _classify_trade_quality(self, trade_record: TradeRecord) -> int:
        """åˆ†ç±»äº¤æ˜“è´¨é‡"""
        if trade_record.profit_pct > 5:
            return 4  # ä¼˜ç§€
        elif trade_record.profit_pct > 2:
            return 3  # è‰¯å¥½
        elif trade_record.profit_pct > 0:
            return 2  # ä¸€èˆ¬
        elif trade_record.profit_pct > -2:
            return 1  # è¾ƒå·®
        else:
            return 0  # å¾ˆå·®
    
    def train_batch_models(self, batch_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """æ‰¹é‡è®­ç»ƒæ¨¡å‹"""
        
        print("ğŸ¯ å¼€å§‹æ‰¹é‡æ¨¡å‹è®­ç»ƒ...")
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_data = []
        for symbol, data in batch_data.items():
            data['symbol'] = symbol
            all_data.append(data)
        
        if not all_data:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®")
        
        combined_data = pd.concat(all_data, ignore_index=True)
        print(f"ğŸ“Š åˆå¹¶æ•°æ®: {len(combined_data)} ä¸ªæ ·æœ¬")
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        feature_columns = [col for col in combined_data.columns 
                          if not col.startswith(('profit_', 'risk_adjusted_', 'holding_', 'exit_', 'trade_', 'symbol', 'interval', 'entry_time', 'trade_id'))]
        
        X = combined_data[feature_columns].fillna(0)
        
        # å¤šç›®æ ‡è®­ç»ƒ
        targets = {
            'profit_predictor': 'profit_pct',
            'risk_adjusted_predictor': 'risk_adjusted_return', 
            'efficiency_predictor': 'holding_efficiency',
            'exit_timing_predictor': 'exit_timing_score',
            'quality_classifier': 'trade_quality'
        }
        
        trained_models = {}
        performance_metrics = {}
        
        for model_name, target_col in targets.items():
            print(f"\nğŸ”„ è®­ç»ƒ {model_name}...")
            
            if target_col not in combined_data.columns:
                print(f"âš ï¸  ç›®æ ‡åˆ— {target_col} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            
            y = combined_data[target_col].fillna(0)
            
            # æ•°æ®åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=self.config.test_size, random_state=42
            )
            
            # é€‰æ‹©æ¨¡å‹
            if model_name == 'quality_classifier':
                from sklearn.ensemble import RandomForestClassifier
                model = RandomForestClassifier(n_estimators=100, random_state=42)
            else:
                model = RandomForestRegressor(n_estimators=100, random_state=42)
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train_scaled, y_train)
            
            # è¯„ä¼°æ¨¡å‹
            train_score = model.score(X_train_scaled, y_train)
            test_score = model.score(X_test_scaled, y_test)
            
            print(f"   è®­ç»ƒå¾—åˆ†: {train_score:.3f}")
            print(f"   æµ‹è¯•å¾—åˆ†: {test_score:.3f}")
            
            # ä¿å­˜æ¨¡å‹å’Œè¯„ä¼°ç»“æœ
            trained_models[model_name] = {
                'model': model,
                'scaler': scaler,
                'feature_columns': feature_columns,
                'target_column': target_col
            }
            
            performance_metrics[model_name] = {
                'train_score': train_score,
                'test_score': test_score,
                'feature_importance': dict(zip(feature_columns, model.feature_importances_)) if hasattr(model, 'feature_importances_') else {}
            }
        
        print(f"\nâœ… æ‰¹é‡è®­ç»ƒå®Œæˆ: {len(trained_models)} ä¸ªæ¨¡å‹")
        
        # ä¿å­˜ç»“æœ
        self.trained_models = trained_models
        self.performance_metrics = performance_metrics
        
        return {
            'models': trained_models,
            'metrics': performance_metrics,
            'feature_columns': feature_columns
        }
    
    def optimize_strategy_parameters(self, symbol: str, interval: str, 
                                   current_params: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºè®­ç»ƒç»“æœä¼˜åŒ–ç­–ç•¥å‚æ•°"""
        
        if not self.trained_models:
            raise ValueError("æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œæ‰¹é‡è®­ç»ƒ")
        
        print(f"ğŸ”§ ä¸º {symbol} {interval} ä¼˜åŒ–ç­–ç•¥å‚æ•°...")
        
        # åŠ è½½å½“å‰å¸‚åœºæ•°æ®
        try:
            from data_utils import load_local_data
            current_data = load_local_data(symbol, interval)
            
            if current_data is None:
                raise ValueError(f"æ— æ³•åŠ è½½ {symbol} {interval} æ•°æ®")
            
            # æå–å½“å‰å¸‚åœºç‰¹å¾
            recent_data = current_data.tail(100)  # ä½¿ç”¨æœ€è¿‘100æ ¹Kçº¿
            current_features = self._extract_comprehensive_features(recent_data, 
                                                                   TradeRecord("", symbol, interval, "", "", 0, 0, "buy", 0, 0, 0, 0, 0, "", 3, 0.5, True, True, 0.02, 0.5))
            
            # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹
            predictions = self._predict_with_ensemble(current_features)
            
            # åŸºäºé¢„æµ‹ç»“æœè°ƒæ•´å‚æ•°
            optimized_params = self._adjust_parameters_based_predictions(
                current_params, predictions, symbol, interval
            )
            
            print("ğŸ“Š å‚æ•°ä¼˜åŒ–å®Œæˆ:")
            for param, value in optimized_params.items():
                if param in current_params:
                    old_value = current_params[param]
                    change = "ğŸ“ˆ" if value > old_value else "ğŸ“‰" if value < old_value else "â¡ï¸"
                    print(f"   {param}: {old_value} â†’ {value} {change}")
                else:
                    print(f"   {param}: {value} (æ–°å¢)")
            
            return optimized_params
            
        except Exception as e:
            print(f"âŒ å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return current_params
    
    def _predict_with_ensemble(self, features: Dict[str, float]) -> Dict[str, float]:
        """ä½¿ç”¨é›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        
        predictions = {}
        
        for model_name, model_data in self.trained_models.items():
            try:
                model = model_data['model']
                scaler = model_data['scaler']
                feature_columns = model_data['feature_columns']
                
                # å‡†å¤‡ç‰¹å¾å‘é‡
                feature_vector = []
                for col in feature_columns:
                    feature_vector.append(features.get(col, 0))
                
                # æ ‡å‡†åŒ–å’Œé¢„æµ‹
                feature_vector = np.array(feature_vector).reshape(1, -1)
                feature_vector_scaled = scaler.transform(feature_vector)
                
                prediction = model.predict(feature_vector_scaled)[0]
                predictions[model_name] = prediction
                
            except Exception as e:
                print(f"âš ï¸  {model_name} é¢„æµ‹å¤±è´¥: {e}")
                predictions[model_name] = 0
        
        return predictions
    
    def _adjust_parameters_based_predictions(self, current_params: Dict[str, Any], 
                                           predictions: Dict[str, float],
                                           symbol: str, interval: str) -> Dict[str, Any]:
        """åŸºäºé¢„æµ‹ç»“æœè°ƒæ•´å‚æ•°"""
        
        optimized_params = current_params.copy()
        
        # æ ¹æ®ç›ˆåˆ©é¢„æµ‹è°ƒæ•´ä¿¡å·é˜ˆå€¼
        expected_profit = predictions.get('profit_predictor', 0)
        if expected_profit > 3:  # é¢„æœŸç›ˆåˆ©>3%
            optimized_params['min_signal_score'] = max(1, current_params.get('min_signal_score', 3) - 1)
            optimized_params['min_shadow_body_ratio'] = max(1.0, current_params.get('min_shadow_body_ratio', 2.0) - 0.2)
        elif expected_profit < 0:  # é¢„æœŸäºæŸ
            optimized_params['min_signal_score'] = min(5, current_params.get('min_signal_score', 3) + 1)
            optimized_params['min_shadow_body_ratio'] = min(4.0, current_params.get('min_shadow_body_ratio', 2.0) + 0.3)
        
        # æ ¹æ®é€€å‡ºæ—¶æœºé¢„æµ‹è°ƒæ•´æ­¢ç›ˆç­–ç•¥
        exit_timing_score = predictions.get('exit_timing_predictor', 0.5)
        if exit_timing_score < 0.3:  # å†å²ä¸Šç»å¸¸è¿‡æ—©é€€å‡º
            optimized_params['trend_profit_extension'] = True
            optimized_params['max_trend_profit_pct'] = min(20.0, current_params.get('max_trend_profit_pct', 8.0) * 1.5)
        elif exit_timing_score > 0.8:  # å†å²ä¸Šé€€å‡ºæ—¶æœºå¾ˆå¥½
            optimized_params['trend_profit_extension'] = False
            optimized_params['max_trend_profit_pct'] = max(5.0, current_params.get('max_trend_profit_pct', 8.0) * 0.8)
        
        # æ ¹æ®æŒä»“æ•ˆç‡è°ƒæ•´
        efficiency = predictions.get('efficiency_predictor', 0)
        if efficiency > 0.5:  # æŒä»“æ•ˆç‡é«˜
            optimized_params['enable_trend_tracking'] = True
            optimized_params['trailing_stop_buffer'] = min(3.0, current_params.get('trailing_stop_buffer', 1.5) * 1.2)
        
        # æ ¹æ®é£é™©è°ƒæ•´æ”¶ç›Šé¢„æµ‹è°ƒæ•´æ æ†
        risk_adjusted_return = predictions.get('risk_adjusted_predictor', 0)
        if risk_adjusted_return > 2:  # é£é™©è°ƒæ•´æ”¶ç›Šå¥½
            optimized_params['leverage_multiplier'] = min(1.5, current_params.get('leverage_multiplier', 1.0) + 0.2)
        elif risk_adjusted_return < 0:  # é£é™©è°ƒæ•´æ”¶ç›Šå·®
            optimized_params['leverage_multiplier'] = max(0.5, current_params.get('leverage_multiplier', 1.0) - 0.2)
        
        return optimized_params
    
    def save_batch_models(self, output_dir: str = None) -> str:
        """ä¿å­˜æ‰¹é‡è®­ç»ƒçš„æ¨¡å‹"""
        
        if output_dir is None:
            output_dir = self.config.model_output_dir
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(output_dir, f"batch_models_{timestamp}.pkl")
        
        save_data = {
            'models': self.trained_models,
            'metrics': self.performance_metrics,
            'config': self.config,
            'timestamp': timestamp
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(save_data, f)
        
        print(f"ğŸ’¾ æ‰¹é‡æ¨¡å‹å·²ä¿å­˜: {save_path}")
        return save_path
    
    def load_batch_models(self, model_path: str):
        """åŠ è½½æ‰¹é‡è®­ç»ƒçš„æ¨¡å‹"""
        
        with open(model_path, 'rb') as f:
            save_data = pickle.load(f)
        
        self.trained_models = save_data['models']
        self.performance_metrics = save_data['metrics']
        
        print(f"âœ… æ‰¹é‡æ¨¡å‹å·²åŠ è½½: {model_path}")
        print(f"   åŒ…å« {len(self.trained_models)} ä¸ªæ¨¡å‹")
    
    def generate_optimization_report(self, symbol: str, predictions: Dict[str, float], 
                                   old_params: Dict[str, Any], new_params: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        
        report = f"""
ğŸ“Š ç­–ç•¥å‚æ•°ä¼˜åŒ–æŠ¥å‘Š - {symbol}
{'='*60}
ğŸ¤– MLé¢„æµ‹ç»“æœ:
  - é¢„æœŸç›ˆåˆ©ç‡: {predictions.get('profit_predictor', 0):.2f}%
  - é£é™©è°ƒæ•´æ”¶ç›Š: {predictions.get('risk_adjusted_predictor', 0):.2f}
  - æŒä»“æ•ˆç‡: {predictions.get('efficiency_predictor', 0):.3f}
  - é€€å‡ºæ—¶æœºè¯„åˆ†: {predictions.get('exit_timing_predictor', 0):.3f}
  - äº¤æ˜“è´¨é‡è¯„åˆ†: {predictions.get('quality_classifier', 0):.1f}/4

ğŸ”§ å‚æ•°ä¼˜åŒ–ç»“æœ:
"""
        
        for param in new_params:
            old_val = old_params.get(param, "æœªè®¾ç½®")
            new_val = new_params[param]
            
            if param in old_params and old_params[param] != new_val:
                change_pct = ((new_val - old_params[param]) / old_params[param] * 100) if isinstance(old_params[param], (int, float)) and old_params[param] != 0 else 0
                report += f"  - {param}: {old_val} â†’ {new_val} ({change_pct:+.1f}%)\n"
            elif param not in old_params:
                report += f"  - {param}: {new_val} (æ–°å¢)\n"
        
        return report

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    if ML_AVAILABLE:
        print("ğŸ¯ æ‰¹é‡è®­ç»ƒæ•°æ®ç³»ç»Ÿå·²å°±ç»ª")
        print("   æ”¯æŒå¤šå¸ç§ã€å¤šæ¨¡å‹ååŒè®­ç»ƒ")
        print("   æä¾›åŸºäºå†å²äº¤æ˜“è®°å½•çš„å‚æ•°ä¼˜åŒ–")
    else:
        print("âŒ æœºå™¨å­¦ä¹ æ¨¡å—æœªå®‰è£…ï¼Œè¯·å®‰è£…scikit-learn")